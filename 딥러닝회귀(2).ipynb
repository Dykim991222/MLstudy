{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbNzmylGWjMOpojauUKnXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dykim991222/MLstudy/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%9A%8C%EA%B7%80(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pc1ZDONohf_n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴퓨터에 있는 random seed table 은 컴퓨터 마다 다르므로\n",
        "# 현재 실습하고 있는 파이썬코드를 재실행해도 같은 결과가 나오게끔\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okzHTCr_l11q",
        "outputId": "1cd5d009-ee38-46ef-a485-c81645ca38ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7de35ff9d1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "UIIwDlTPn-Zj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1menjJxoRUe",
        "outputId": "27c2e799-a609-429d-db2e-2a04412f9206"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.]]),\n",
              " tensor([[2.],\n",
              "         [4.],\n",
              "         [6.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9FMGzMJoSpk",
        "outputId": "2248461a-a553-49c4-e54e-566153152505"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 1]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "optimizer = optim.SGD([W,b], lr=0.001)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs+1):\n",
        "  # 예측하기\n",
        "  predict = X_train * W + b\n",
        "\n",
        "  # 틀린 정도 계산하기\n",
        "  cost = torch.mean((predict - y_train) ** 2)\n",
        "\n",
        "  # 이전 step에서 계산된 gradient가 남아있을 수 있어서 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 틀린 정도(cost)를 기준으로  W, b를 얼마나 덜 틀리는지.\n",
        "  # 기울기(gradient)를 계산한다.\n",
        "  cost.backward()\n",
        "\n",
        "  # 실제로 고치기. 계산된 gradient로 W, b값 수정하기\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"Epoch : {:4d}/{}, W:{:.3f}, b:{:.3f}, Cost: {:.6f}\".format(\n",
        "        epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IVzCdW7ob1D",
        "outputId": "7cbfa2ac-f919-4695-972a-3b3f5b23e561"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :    0/100, W:0.019, b:0.008, Cost: 18.666666\n",
            "Epoch :   10/100, W:0.194, b:0.083, Cost: 14.949220\n",
            "Epoch :   20/100, W:0.352, b:0.150, Cost: 11.975055\n",
            "Epoch :   30/100, W:0.492, b:0.210, Cost: 9.595544\n",
            "Epoch :   40/100, W:0.618, b:0.263, Cost: 7.691776\n",
            "Epoch :   50/100, W:0.731, b:0.311, Cost: 6.168622\n",
            "Epoch :   60/100, W:0.832, b:0.353, Cost: 4.949974\n",
            "Epoch :   70/100, W:0.922, b:0.391, Cost: 3.974937\n",
            "Epoch :   80/100, W:1.003, b:0.424, Cost: 3.194803\n",
            "Epoch :   90/100, W:1.076, b:0.454, Cost: 2.570597\n",
            "Epoch :  100/100, W:1.140, b:0.481, Cost: 2.071139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer.zero_grad()가 필요한 이유\n",
        "\n",
        "파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있음.\n",
        "\n",
        "딥러닝 은 입력층과 출력층 사이에 여러개의 은닉층으로 이루어진 신경망이다. 층이 깊어질수록 모듈과 함수에 따른 하이퍼파라미터도 비례하여 많아지기에 이를 정확히 결정해 좋은 결과를 뱉어낼 수 있도록 하는것이 핵심.\n",
        "\n",
        "Loss Function : 얼마나 틀리는지를 알게 하는 함수\n",
        "\n",
        "Optimization : 최소값을 찾아가는 것. 최적화\n",
        "\n",
        "Optimizer : 최적화 알고리즘"
      ],
      "metadata": {
        "id": "LY-CQhVoGRmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "optimizer = optim.SGD([w], lr=0.01)\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs+1):\n",
        "  #optimizer.zero_grad()\n",
        "  z = 2 * w\n",
        "  z.backward()\n",
        "  print('수식을 w로 미분한 값 : {}'.format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfiulRTCpoUJ",
        "outputId": "54fc790e-5b57-448a-df8e-af32c6562348"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 2.0\n",
            "수식을 w로 미분한 값 : 4.0\n",
            "수식을 w로 미분한 값 : 6.0\n",
            "수식을 w로 미분한 값 : 8.0\n",
            "수식을 w로 미분한 값 : 10.0\n",
            "수식을 w로 미분한 값 : 12.0\n",
            "수식을 w로 미분한 값 : 14.0\n",
            "수식을 w로 미분한 값 : 16.0\n",
            "수식을 w로 미분한 값 : 18.0\n",
            "수식을 w로 미분한 값 : 20.0\n",
            "수식을 w로 미분한 값 : 22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다중 선형 회귀를 matmul로 구현해보기\n",
        "\n",
        "y = WX + WX + WX + b\n",
        "\n",
        "# 특징\n",
        "\n",
        "W, b를 직접 정의\n",
        "\n",
        "**행렬곱(matmul)**으로 직접 선형 회귀식을 구현\n",
        "\n",
        "신경망의 기본 구조(선형변환 → 오차 → 미분 → 옵티마이저 업데이트)를\n",
        "가장 로우레벨에서 직접 체험함\n",
        "\n",
        "실제로는 모델 구조가 단순할 때만 사용 가능\n",
        "\n",
        "#  배우는 이유\n",
        "\n",
        "신경망의 기본 동작 원리(Forward → Loss → Backward → Update)를 이해\n",
        "\n",
        "선형 회귀, Perceptron, MLP 기본을 완전히 이해하게 됨\n",
        "\n",
        "이후 복잡한 모델을 만들 때 “왜 이렇게 작동하지?” 를 파악하게 됨\n",
        "\n",
        "즉, 딥러닝의 기초 체력을 만드는 데 필수."
      ],
      "metadata": {
        "id": "WsazLn1WHtLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "ieWnNX8qHWOz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYwXCU8EH1SJ",
        "outputId": "403d9d0b-2bbd-49ec-cf9c-bb2512ad92f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros((3,1), requires_grad=True)\n",
        "b = torch.zeros((1), requires_grad=True)"
      ],
      "metadata": {
        "id": "agpkulPDH4k4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값이 튈 수 있으니 정규화 진행하기.\n",
        "x_mean = x_train.mean(dim=0)\n",
        "x_std = x_train.std(dim=0)\n",
        "x_norm = (x_train - x_mean) / x_std\n",
        "\n",
        "y_mean = y_train.mean(dim=0)\n",
        "y_std = y_train.std(dim=0)\n",
        "y_norm = (y_train-y_mean) / y_std\n",
        "\n",
        "# 가중치, 편향 설정\n",
        "W = torch.zeros((3,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "    predict = x_norm.matmul(W) + b\n",
        "    cost = torch.mean((predict - y_norm) ** 2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f} \"\n",
        "              f\"W: {W.squeeze().detach().tolist()} b: {b.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7pZmr5IHhX",
        "outputId": "29f42b4f-e3cf-46df-a718-f935aa747f43"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.800000 W: [0.01576147973537445, 0.01520462241023779, 0.014837720431387424] b: 0.0000\n",
            "Epoch  100/1000 Cost: 0.007364 W: [0.37443259358406067, 0.34778907895088196, 0.30188223719596863] b: -0.0000\n",
            "Epoch  200/1000 Cost: 0.005482 W: [0.4034954309463501, 0.35840514302253723, 0.272542804479599] b: 0.0000\n",
            "Epoch  300/1000 Cost: 0.004160 W: [0.4263972043991089, 0.3631184995174408, 0.24479912221431732] b: 0.0000\n",
            "Epoch  400/1000 Cost: 0.003174 W: [0.44686025381088257, 0.36598533391952515, 0.2212372124195099] b: 0.0000\n",
            "Epoch  500/1000 Cost: 0.002433 W: [0.46513915061950684, 0.36753329634666443, 0.20118972659111023] b: 0.0000\n",
            "Epoch  600/1000 Cost: 0.001872 W: [0.4814404547214508, 0.36813485622406006, 0.18408076465129852] b: 0.0000\n",
            "Epoch  700/1000 Cost: 0.001445 W: [0.4959574341773987, 0.36807018518447876, 0.16943778097629547] b: 0.0000\n",
            "Epoch  800/1000 Cost: 0.001119 W: [0.5088695883750916, 0.3675490915775299, 0.156871497631073] b: 0.0000\n",
            "Epoch  900/1000 Cost: 0.000869 W: [0.5203418731689453, 0.3667280375957489, 0.14606033265590668] b: 0.0000\n",
            "Epoch 1000/1000 Cost: 0.000677 W: [0.5305252075195312, 0.3657221794128418, 0.13673749566078186] b: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다중 선형 회귀를 nn과 F를 이용해서 학습해보자\n",
        "\n",
        "# 특징\n",
        "\n",
        "모델을 모듈화하여 관리 (계층 개수 늘리기 쉬움)\n",
        "\n",
        "deep learning 전체 구조에 필요한 자동 독립성 & 유지보수 용이\n",
        "\n",
        "레이어가 늘어나면 자동으로 파라미터 관리됨\n",
        "\n",
        "실전 프로젝트에서는 대부분 이걸 씀\n",
        "\n",
        "# 배우는 이유\n",
        "\n",
        "CNN, RNN, Transformer 등 모든 딥러닝 구조를 이 방식으로 만들어야 함\n",
        "\n",
        "실전 학습 코드 구성 능력을 얻게 됨\n",
        "\n",
        "확장성 (레이어 추가, dropout, batchnorm 등) 제공"
      ],
      "metadata": {
        "id": "R431QA0Faiu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "2o5pE1C1Isrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37039a9-0b43-41ab-9437-a4d4b9aa6be3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7de35ff9d1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "nYOwGlWAqbWT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3, 1)"
      ],
      "metadata": {
        "id": "7ZgVQ3X9efcf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kibfsu2ejEj",
        "outputId": "e0cb0628-2577-4eab-c08c-02131cc036eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train은 3개의 특성, 5개의 데이터.\n",
        "# 따라서 열 기준으로 평균, 표준편차 구하고 정규화\n",
        "x_mean = x_train.mean(dim=0)\n",
        "x_std = x_train.std(dim=0)\n",
        "x_norm = (x_train - x_mean) / x_std\n",
        "\n",
        "y_mean = y_train.mean(dim=0)\n",
        "y_std = y_train.std(dim=0)\n",
        "y_norm = (y_train - y_mean) / y_std"
      ],
      "metadata": {
        "id": "6ODk81Q7az6J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "nb_epochs = 1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  predict = model(x_train)\n",
        "  cost = F.mse_loss(predict, y_norm)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{}, Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LerJ2aWAdfvr",
        "outputId": "39b97c93-e93d-4bbf-ba8e-f531eb3c1ff6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000, Cost: 0.176423\n",
            "Epoch  100/1000, Cost: 0.176324\n",
            "Epoch  200/1000, Cost: 0.176226\n",
            "Epoch  300/1000, Cost: 0.176129\n",
            "Epoch  400/1000, Cost: 0.176032\n",
            "Epoch  500/1000, Cost: 0.175935\n",
            "Epoch  600/1000, Cost: 0.175839\n",
            "Epoch  700/1000, Cost: 0.175743\n",
            "Epoch  800/1000, Cost: 0.175646\n",
            "Epoch  900/1000, Cost: 0.175550\n",
            "Epoch 1000/1000, Cost: 0.175453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 데이터로 학습된 모델에 넣어 예측해보기"
      ],
      "metadata": {
        "id": "iGKYaWrkiWvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 값들\n",
        "x_mean = x_train.mean(dim=0)\n",
        "x_std = x_train.std(dim=0)\n",
        "\n",
        "y_mean = y_train.mean()\n",
        "y_std = y_train.std()\n",
        "\n",
        "# 새로운 입력\n",
        "new_var = torch.FloatTensor([[73, 80, 75]])\n",
        "\n",
        "# 1) 입력 정규화\n",
        "new_var_norm = (new_var - x_mean) / x_std\n",
        "\n",
        "# 2) 모델 예측\n",
        "pred_y_norm = model(new_var_norm)\n",
        "\n",
        "# 3) 역정규화\n",
        "pred_y = pred_y_norm * y_std + y_mean\n",
        "\n",
        "print(\"예측된 실제 y값:\", pred_y.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1DbBa3XeSMt",
        "outputId": "2c813779-b946-437b-d20b-31b6e6ffb93b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측된 실제 y값: 80.26888275146484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다중 선형회귀 클래스형태로 구현해보기"
      ],
      "metadata": {
        "id": "GFm9R_TM0ytd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "q1FUrkyfioRk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "3EoKU8Ml1C6K"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() # nn.Module 상속\n",
        "    # super()로 기반 클래스(부모 클래스) 를 초기화해줌으로써,\n",
        "    # 기반 클래스의 속성을 subclass가 받아오도록 한다.\n",
        "    # (초기화를 하지 않으면, 부모 클래스의 속성 사용 X)\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "6Qt7uYrZ1Eap"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultivariateLinearRegression()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)"
      ],
      "metadata": {
        "id": "OLFXzZGT10mN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  # 모델\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # cost 꼐산\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  optimizer.zero_grad() # gradient 를 0으로 초기화\n",
        "  cost.backward() # cost function  미분하여 gradient 계산\n",
        "  optimizer.step() # W와 b 업데이트\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "    print('Epoch {}/{} cost {:.3f} '.format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pQUUo7y19jd",
        "outputId": "e5c29571-3a11-461f-91cc-608312288733"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2000 cost 0.432 \n",
            "Epoch 500/2000 cost 0.415 \n",
            "Epoch 1000/2000 cost 0.401 \n",
            "Epoch 1500/2000 cost 0.389 \n",
            "Epoch 2000/2000 cost 0.379 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 미니배치 학습을 구현해보자"
      ],
      "metadata": {
        "id": "snsiODGb3Elt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "SD-D8l5v2lPb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "y2Vx1hCn3MjC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  90],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "hGGILaQz3ROd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(x_train, y_train)\n",
        "'''\n",
        "[\n",
        "  ([73, 80, 75], [152]),\n",
        "  ([93, 88, 93], [185]),\n",
        "  ([89, 91, 90], [180]),\n",
        "  ([96, 98, 100], [196]),\n",
        "  ([73, 66, 70], [142]),\n",
        "]\n",
        "입력과 정답을 튜플 형태(입력->정답) 형태로 학습\n",
        "'''\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "'''\n",
        "Batch 1:\n",
        "([73, 80, 75], [152])\n",
        "([93, 88, 93], [185])\n",
        "Batch 2:\n",
        "([89, 91, 90], [180])\n",
        "([96, 98, 100], [196])\n",
        "Batch 3:\n",
        "([73, 66, 70], [142])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2d8Qyjcm3VZL",
        "outputId": "423f9e7c-b836-4a0b-8801-4fa1756c55e8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nBatch 1:\\n([73, 80, 75], [152])\\n([93, 88, 93], [185])\\nBatch 2:\\n([89, 91, 90], [180])\\n([96, 98, 100], [196])\\nBatch 3:\\n([73, 66, 70], [142])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3, 1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "Fj7LPf553gww"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 3\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    print(batch_idx)\n",
        "    print(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a-si7Zq4gaz",
        "outputId": "32573ce6-85bd-47e7-f692-9c2e05ad58fb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[tensor([[73., 80., 75.],\n",
            "        [73., 66., 70.]]), tensor([[152.],\n",
            "        [142.]])]\n",
            "1\n",
            "[tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "0\n",
            "[tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "1\n",
            "[tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "0\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "1\n",
            "[tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "2\n",
            "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "0\n",
            "[tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "1\n",
            "[tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])]\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if epoch % 400 == 0:\n",
        "    print(\"Epoch : {}/{}, Cost : {:.3f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyhHPKQf4uGN",
        "outputId": "148fd8f4-59df-4d80-8ba8-b040f5d29d38"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0/2000, Cost : 0.615\n",
            "Epoch : 400/2000, Cost : 0.543\n",
            "Epoch : 800/2000, Cost : 0.684\n",
            "Epoch : 1200/2000, Cost : 0.055\n",
            "Epoch : 1600/2000, Cost : 0.593\n",
            "Epoch : 2000/2000, Cost : 0.113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실습) 다음 조건을 만족하는 다중 선형회귀 학습을 짜시오\n",
        "\n",
        "1. 데이터는 아래 데이터 그대로 사용할 것\n",
        "2. 그에 맞는 다중 선형회귀를 클래스 형태로 짤 것.\n",
        "3. 미니배치사이즈 4\n",
        "4. 에폭 100\n",
        "5. 옵티마이저, loss 마음대로 선택. 단, 성능은 신경쓰지 말 것.\n",
        "6. import는 마음대로 넣을 것.\n",
        "7. x_test 변수를 이용해 예측해서 결과를 출력하고 기울기함수를 해제하시오: detach 사용"
      ],
      "metadata": {
        "id": "gSoI1y978aqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75, 88],\n",
        "                               [93,  88,  93, 87],\n",
        "                               [89,  91,  90, 95],\n",
        "                               [96,  98,  93, 95],\n",
        "                               [73,  66,  70, 77],\n",
        "                               [77,  82,  75, 86],\n",
        "                               [88,  75,  91, 90]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142], [151], [155]])\n",
        "\n",
        "x_mean = x_train.mean(dim=0)\n",
        "x_std = x_train.std(dim=0)\n",
        "x_norm = (x_train - x_mean) / x_std\n",
        "\n",
        "y_mean = y_train.mean(dim=0)\n",
        "y_std = y_train.std(dim=0)\n",
        "y_norm = (y_train - y_mean) / y_std\n",
        "\n",
        "dataset = TensorDataset(x_norm, y_norm)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "class MultivariateLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegression()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "\n",
        "    x_train2, y_train2 = samples\n",
        "    prediction = model(x_train2)\n",
        "    cost = F.mse_loss(prediction, y_train2)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print(\"Epoch : {}/{}, Cost : {:.3f}\".format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbAqiwD15jT5",
        "outputId": "a4476e33-7248-4538-d0f2-6bcd924029a3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0/10, Cost : 0.644\n",
            "Epoch : 2/10, Cost : 1.024\n",
            "Epoch : 4/10, Cost : 0.403\n",
            "Epoch : 6/10, Cost : 0.826\n",
            "Epoch : 8/10, Cost : 1.383\n",
            "Epoch : 10/10, Cost : 0.580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.FloatTensor([[85, 90, 95, 93]])\n",
        "x_test_norm = (x_test - x_mean) / x_std\n",
        "y_pred_norm = model(x_test_norm)\n",
        "y_pred = y_pred_norm * y_std + y_mean\n",
        "\n",
        "# detach 사용해서 gradient 연결 끊고 값만 가져오기\n",
        "y_pred_value = y_pred.detach().item()\n",
        "\n",
        "print(\"입력값:\", x_test.tolist())\n",
        "print(\"예측값:\", y_pred_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2I4PXel_Xby",
        "outputId": "e2c7bebc-b82b-47a3-9b86-6cf35d4bf6b0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력값: [[85.0, 90.0, 95.0, 93.0]]\n",
            "예측값: 158.80560302734375\n"
          ]
        }
      ]
    }
  ]
}